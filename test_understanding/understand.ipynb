{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F \n",
    "from torch import optim \n",
    "import copy \n",
    "import numpy as np \n",
    "import math \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "\n",
    "def exponential_decrease(idx_decoder,p=3):\n",
    "    return math.exp(-p*idx_decoder)\n",
    "for i in range(3):\n",
    "    print(exponential_decrease(i))\n",
    "\n",
    "A= torch.arange(6,dtype=torch.float32).reshape(2,3)\n",
    "B= torch.tensor([[1.0,2.0,3.0], [1.0,2.0,3.0]])\n",
    "C= torch.rand(2,3,4)\n",
    "\n",
    "softmx_dim_1= nn.Softmax(dim=-1)\n",
    "softmx_dim1= nn.Softmax(dim=1)\n",
    "softmx_0= nn.Softmax(dim=0)\n",
    "print(A,C )\n",
    "print(softmx_dim_1(A)) # add the valus of rows and devide the number of i,j element by sum(rows - i)\n",
    "print(softmx_dim1(A))\n",
    "print(f'{softmx_dim1(B)}, {softmx_0(B)},{softmx_dim_1(B)}')\n",
    "print(f' dim = 1 {softmx_dim1(C)}, dim =0  {softmx_0(C)},dim = -1 {softmx_dim_1(C)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " query torch.Size([2, 64, 10]) key torch.Size([2, 64, 10]) energy torch.Size([2, 10, 10]) c1 64 and  attention  torch.Size([2, 10, 10]) \n",
      "torch.Size([2, 10, 10]) tensor([[[ 9.5367e-07,  9.5367e-07,  9.5367e-07,  9.5367e-07,  9.5367e-07,\n",
      "           9.5367e-07,  9.5367e-07,  9.5367e-07, -1.3816e+01, -1.3816e+01]],\n",
      "\n",
      "        [[ 9.5367e-07,  9.5367e-07,  9.5367e-07,  9.5367e-07,  9.5367e-07,\n",
      "           9.5367e-07,  9.5367e-07,  9.5367e-07,  9.5367e-07, -1.3816e+01]]])\n",
      "torch.Size([2, 10, 10])\n",
      "torch.Size([2, 10, 10])\n",
      "torch.Size([2, 64, 10])\n",
      "torch.Size([1, 15, 29]) 3\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import torch\n",
    "\n",
    "# Batch size and total sequence length\n",
    "# batch_size = 2\n",
    "# total_seq_length = 10\n",
    "# # Actual lengths of each sequence in the batch\n",
    "# actual_lengths = [8, 9]\n",
    "# # Create an empty mask filled with zeros of shape [batch_size, total_seq_length]\n",
    "# padding_mask = torch.zeros((batch_size, total_seq_length))\n",
    "# # Set positions corresponding to the actual lengths to 1\n",
    "# for i, length in enumerate(actual_lengths):\n",
    "#     padding_mask[i, :length] = 1\n",
    "\n",
    "# print(padding_mask.shape)\n",
    "\n",
    "padding_mask = torch.zeros((2, 10))\n",
    "padding_mask[0, :8] = 1  # First sequence has 8 actual values\n",
    "padding_mask[1, :9] = 1 \n",
    "padding_mask= padding_mask.unsqueeze(1)\n",
    "\n",
    "proj_query= torch.rand(2,64,10)\n",
    "proj_key= torch.rand(2,64,10)\n",
    "proj_val=torch.rand(2,64,10)\n",
    "m,c1,l1= proj_query.shape\n",
    "m,c2,l2= proj_key.shape \n",
    "energy = torch.bmm(proj_query.permute(0,2,1),proj_key) # bmm stands for batch matrix multiplication \n",
    "attention = energy/np.sqrt(c1)\n",
    "print(f' query {proj_query.shape} key {proj_key.shape} energy {energy.shape} c1 {c1} and  attention  {attention.shape} ')\n",
    "attention = attention + torch.log(padding_mask+ 1e-6)\n",
    "print(attention.shape, torch.log(padding_mask + 1e-6) )\n",
    "softmax=nn.Softmax(dim=-1)\n",
    "attention= softmax(attention)\n",
    "attention= attention * padding_mask\n",
    "print(attention.shape)\n",
    "attention = attention.permute(0,2,1)\n",
    "print(attention.shape)\n",
    "\n",
    "out = torch.bmm(proj_val,attention)\n",
    "print(out.shape)\n",
    "\n",
    "bl=15\n",
    "window_mask = torch.zeros((1, bl, bl + 2* (bl //2))) # 1,16,32 | 1,15,29\n",
    "for i in range(bl):\n",
    "    window_mask[:, :, i:i+bl] = 1\n",
    "print(window_mask.shape, len(window_mask.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "class AttentionHelper(nn.Module):\n",
    "    def __init__(self, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.softmax=nn.Softmax(dim=-1)\n",
    "    def scalar_dot_att(self,proj_query,proj_key, proj_val, padding_mask):\n",
    "        '''A\n",
    "        '''\n",
    "        m,c1,l1= proj_query.shape\n",
    "        m,c2,l2= proj_key.shape \n",
    "\n",
    "        assert c1==c2\n",
    "\n",
    "        energy= torch.bmm(proj_query.permute(0,2,1),proj_key)\n",
    "        attention = energy / np.sqrt(c1)\n",
    "        if len(padding_mask.shape) != len(attention.shape):\n",
    "            padding_mask = padding_mask.unsqueeze(1)\n",
    "\n",
    "        attention = attention + torch.log(padding_mask + 1e-6) # mask the zero paddings. log(1e-6) for zero paddings\n",
    "        attention = self.softmax(attention) \n",
    "        attention = attention * padding_mask\n",
    "        attention = attention.permute(0,2,1)\n",
    "        out = torch.bmm(proj_val, attention)\n",
    "        return out, attention\n",
    "    \n",
    "        \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class AttLayer(nn.Module):\n",
    "    def __init__(self,q_dim,k_dim, v_dim,r,block, stage,att_type): # r is the reduction factor \n",
    "        super(AttLayer, self).__init__()\n",
    "        self.query_conv = nn.conv1D(in_channel= q_dim, out_channel= q_dim//r, kernel_size=1)\n",
    "        self.key_conv = nn.conv1D(in_channel= k_dim, out_channel= k_dim//r, kernel_size=1)\n",
    "        self.value_conv = nn.conv1D(in_channel= v_dim, out_channel= v_dim//r, kernel_size=1)\n",
    "\n",
    "        conv_out= nn.conv1D(in_channel= v_dim//r, out_channels= v_dim, kernel_size=1)\n",
    "        self.block = block\n",
    "        self.stage= stage \n",
    "        self.att_type= att_type\n",
    "\n",
    "        assert self.stage in ['encoder', 'decoder']\n",
    "        assert self.att_type in ['normal_att', 'block_att','sliding_att']\n",
    "\n",
    "        self.att_helper= AttentionHelper()\n",
    "        self.window_mask= self.construct_window_mask()\n",
    "    def forward(self, x1, x2, mask):\n",
    "        # x1 from the encoder\n",
    "        # x2 from the decoder\n",
    "        \n",
    "        query = self.query_conv(x1)\n",
    "        key = self.key_conv(x1)\n",
    "         \n",
    "        if self.stage == 'decoder':\n",
    "            assert x2 is not None\n",
    "            value = self.value_conv(x2)\n",
    "        else:\n",
    "            value = self.value_conv(x1)\n",
    "            \n",
    "        if self.att_type == 'normal_att':\n",
    "            return self._normal_self_att(query, key, value, mask)\n",
    "        elif self.att_type == 'block_att':\n",
    "            return self._block_wise_self_att(query, key, value, mask)\n",
    "        elif self.att_type == 'sliding_att':\n",
    "            return self._sliding_window_self_att(query, key, value, mask)\n",
    "\n",
    "\n",
    "    def construct_window_mask(self):\n",
    "        window_mask= torch.zeros((1,self.block,self.block+ 2*(self.block//2)))\n",
    "        for i in range(self.block):\n",
    "            window_mask[:,:,i:i+self.block]= 1\n",
    "        return window_mask.to(device)\n",
    "    \n",
    "    def _sliding_window_self_att(self,q,k,v,mask):\n",
    "        m_batchsize,c1,L = q.size()\n",
    "        _, c2, _ = k.size()\n",
    "        _,c3,_ = v.size()\n",
    "\n",
    "        nb= L//self.block\n",
    "\n",
    "        if L% self.block !=0:  # there is reminder - the remaining sequences \n",
    "            q= torch.cat([q,torch.zeros((m_batchsize,c1,self.block- L % self.block)).to(device)], dim=-1)\n",
    "            k= torch.cat([k,torch.zeros((m_batchsize,c2,self.block - L//self.block)).to(device)], dim =-1)\n",
    "            v= torch.cat([v, torch.zeros((m_batchsize,self.block- L//self.block)).to(device)], dim = -1 )\n",
    "\n",
    "        padding_mask = torch.cat([torch.ones((m_batchsize,1,L)).to(device) * mask[:,0:1,:], torch.zeros((m_batchsize,1,self.block * nb- L)).to(device)], dim = -1 )\n",
    "\n",
    "        # lets expand the block to cover the 1/2 of prior window and posterior window \n",
    "        # the querry is the sliding window and we need to expand the key and value vector \n",
    "\n",
    "        q= q.reshape(m_batchsize,c1,nb,self.block).permute(0,2,1,3).reshape(m_batchsize*nb , c1,self.block)\n",
    "        # extend the k and v for \n",
    "        k = k.reshape(m_batchsize,c2,)\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from libs.utils.preprocess import load_apply_sam_model\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
